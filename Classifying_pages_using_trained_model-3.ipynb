{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5190815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the pages of a pdf\n",
    "#No need to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fb294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Covert pdf to text file\n",
    "#!pip install pdfminer\n",
    "#!pip install io\n",
    "import io\n",
    "from io import StringIO\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    #alltexts = []\n",
    "    filelist=os.listdir(path)\n",
    "    documentcollection=[]\n",
    "    for files in filelist:\n",
    "        files=os.path.join(path,files)\n",
    "        documentcollection.append(files)\n",
    "    for ifiles in documentcollection:\n",
    "        if ifiles.endswith('.pdf') or ifiles.endswith('.PDF'): #different extensions on the raw data\n",
    "            with open(ifiles, 'rb') as fh:\n",
    "                for page in PDFPage.get_pages(fh, \n",
    "                                              caching=True,\n",
    "                                              check_extractable=True):\n",
    "                    resource_manager = PDFResourceManager()\n",
    "                    fake_file_handle = io.StringIO()\n",
    "                    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "                    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "                    page_interpreter.process_page(page)\n",
    " \n",
    "                    text = fake_file_handle.getvalue() # extraction of the text data\n",
    "                    yield text\n",
    " \n",
    "                    # closing open handles\n",
    "                    converter.close()\n",
    "                    fake_file_handle.close()\n",
    "        \n",
    "    #return alltexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc66aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model and a random PDF file to test classification\n",
    "import pickle\n",
    "vectorizer = pickle.load(open('vectorizer.pkl','rb'))\n",
    "NB_model = pickle.load(open('nbmodel.pkl','rb'))\n",
    "RF_model = pickle.load(open('rfmodel.pkl','rb'))\n",
    "XGB_model = pickle.load(open('xgbmodel.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12b0ab4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Data</th>\n",
       "      <th>page_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021 2021 ANNUAL REPORT(A joint stock company ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ProfileThe predecessor of the Bank was Agricul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Annual Report 2021Definitions2Basic Corporate...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Definitions2In this report, unless the context...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3Annual Report 2021Definitions13.H Share(s)Sha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>358Notes to the Consolidated Financial Stateme...</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>359Annual Report 2021Unaudited Supplementary F...</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>360Unaudited Supplementary Financial Informati...</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td></td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2021 2021 ANNUAL REPORT(A joint stock company ...</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text_Data  page_no\n",
       "0    2021 2021 ANNUAL REPORT(A joint stock company ...        1\n",
       "1    ProfileThe predecessor of the Bank was Agricul...        2\n",
       "2    1Annual Report 2021Definitions2Basic Corporate...        3\n",
       "3    Definitions2In this report, unless the context...        4\n",
       "4    3Annual Report 2021Definitions13.H Share(s)Sha...        5\n",
       "..                                                 ...      ...\n",
       "359  358Notes to the Consolidated Financial Stateme...      360\n",
       "360  359Annual Report 2021Unaudited Supplementary F...      361\n",
       "361  360Unaudited Supplementary Financial Informati...      362\n",
       "362                                                  \n",
       "      363\n",
       "363  2021 2021 ANNUAL REPORT(A joint stock company ...      364\n",
       "\n",
       "[364 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the pdf file\n",
    "filepath='/Users/baggu/Downloads/PDF'\n",
    "textcontents = convert_pdf_to_txt(filepath)\n",
    "df_textpages = pd.DataFrame(textcontents, columns = ['Text_Data'])\n",
    "df_textpages['page_no'] = list(range(1,len(df_textpages.index)+1))\n",
    "raw_textpages = df_textpages.copy()\n",
    "df_textpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40b31f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess the data\n",
    "\n",
    "#Defining the pre-preprocessing steps\n",
    "import nltk\n",
    "# Needed only once\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "import re, unidecode, string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text\n",
    "def remove_accented_chars(text):\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text\n",
    "def remove_numbers(text): \n",
    "    result = re.sub(r'\\d+', '', text) \n",
    "    return result\n",
    "def remove_slash_with_space(text): \n",
    "    return text.replace('\\\\', \" \")\n",
    "def remove_punctuation(text): \n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    return text.translate(translator) \n",
    "def text_lowercase(text): \n",
    "    return text.lower()     \n",
    "def remove_whitespace(text): \n",
    "    return  \" \".join(text.split()) \n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return ' '.join(filtered_text)\n",
    "def stem_words(text): \n",
    "    stemmer = PorterStemmer() \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    return ' '.join(stems)\n",
    "def lemmatize_words(text): \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    word_tokens = word_tokenize(text) \n",
    "    # provide context i.e. part-of-speech \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return ' '.join(lemmas) \n",
    "\n",
    "# Perform preprocessing\n",
    "def perform_preprocessing(text):\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_accented_chars(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = text_lowercase(text)\n",
    "    text = remove_slash_with_space(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = stem_words(text)\n",
    "    #text = lemmatize_words(text)\n",
    "    text = remove_whitespace(text)\n",
    "    return text\n",
    "\n",
    "df_textpages.Text_Data = df_textpages.Text_Data.apply(perform_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f29fc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 963)\n"
     ]
    }
   ],
   "source": [
    "inputs = vectorizer.transform(df_textpages.Text_Data)\n",
    "print(inputs.shape)\n",
    "#print(type(inputs))\n",
    "#print(vectorizer.get_feature_names_out())\n",
    "#print(inputs.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf7f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the category of the input file with the help of trained model\n",
    "\n",
    "output_XGB = XGB_model.predict(inputs)\n",
    "#Comment the next line if you are testing word2vec model as it doesn't require transformation\n",
    "#output_category = (labelencoder.inverse_transform((output_category)))\n",
    "#print(output_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae8deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Data</th>\n",
       "      <th>page_no</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021 2021 ANNUAL REPORT(A joint stock company ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ProfileThe predecessor of the Bank was Agricul...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Annual Report 2021Definitions2Basic Corporate...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Definitions2In this report, unless the context...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3Annual Report 2021Definitions13.H Share(s)Sha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>358Notes to the Consolidated Financial Stateme...</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>359Annual Report 2021Unaudited Supplementary F...</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>360Unaudited Supplementary Financial Informati...</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td></td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2021 2021 ANNUAL REPORT(A joint stock company ...</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Text_Data  page_no  output\n",
       "0    2021 2021 ANNUAL REPORT(A joint stock company ...        1       1\n",
       "1    ProfileThe predecessor of the Bank was Agricul...        2       1\n",
       "2    1Annual Report 2021Definitions2Basic Corporate...        3       1\n",
       "3    Definitions2In this report, unless the context...        4       1\n",
       "4    3Annual Report 2021Definitions13.H Share(s)Sha...        5       1\n",
       "..                                                 ...      ...     ...\n",
       "359  358Notes to the Consolidated Financial Stateme...      360       0\n",
       "360  359Annual Report 2021Unaudited Supplementary F...      361       2\n",
       "361  360Unaudited Supplementary Financial Informati...      362       1\n",
       "362                                                  \n",
       "      363       1\n",
       "363  2021 2021 ANNUAL REPORT(A joint stock company ...      364       1\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_textpages['output'] = output_XGB\n",
    "display(raw_textpages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b20d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Prediction_test_2.xlsx'\n",
    "raw_textpages.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b36042e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Financial Statement Pages :\n",
      " [202, 203, 204, 205, 206, 207, 208, 360]\n",
      "\n",
      " Financial Notes Pages :\n",
      " [76, 192, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361]\n",
      "\n",
      " Junk Pages :\n",
      " [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 242, 244, 362, 363, 364]\n"
     ]
    }
   ],
   "source": [
    "# selecting rows category wise\n",
    "\n",
    "FS_df = raw_textpages.loc[raw_textpages['output'] == 0]\n",
    "print('\\n Financial Statement Pages :\\n', list(FS_df.page_no))\n",
    "\n",
    "Notes_df = raw_textpages.loc[raw_textpages['output'] == 2]\n",
    "print('\\n Financial Notes Pages :\\n', list(Notes_df.page_no))\n",
    "\n",
    "Junk_df = raw_textpages.loc[raw_textpages['output'] == 1]\n",
    "print('\\n Junk Pages :\\n', list(Junk_df.page_no))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
